from typing import List, Dict, Any, Optional, Literal
from pydantic import BaseModel, Field
from langchain_core.memory import BaseMemory
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
import time
import uuid
import logging
import json
import re
from dataclasses import dataclass

logger = logging.getLogger(__name__)

class BrainNode(BaseModel):
    """æ€ç»´é“¾èŠ‚ç‚¹"""
    id: str = Field(..., description="èŠ‚ç‚¹å”¯ä¸€æ ‡è¯†ç¬¦")
    content: str = Field(..., description="èŠ‚ç‚¹å†…å®¹")
    timestamp: float = Field(..., description="èŠ‚ç‚¹åˆ›å»ºæ—¶é—´æˆ³")
    parent_id: Optional[str] = Field(None, description="çˆ¶èŠ‚ç‚¹ID")
    host_reply: str = Field("", description="ä¸»æŒäººå›å¤")
    reply_type: str = Field("irrelevant", description="å›å¤ç±»å‹")
    notes: str = Field("", description="å¤‡æ³¨ä¿¡æ¯")

    class Config:
        arbitrary_types_allowed = True

class BrainChain(BaseModel):
    """æ€ç»´é“¾"""
    chain_id: Optional[str] = Field(None, description="æ€ç»´é“¾å”¯ä¸€æ ‡è¯†ç¬¦")
    nodes: Dict[str, BrainNode] = Field(default_factory=dict, description="èŠ‚ç‚¹å­˜å‚¨")
    root_node_id: Optional[str] = Field(None, description="æ ¹èŠ‚ç‚¹ID")
    current_focus_id: Optional[str] = Field(None, description="å½“å‰ç„¦ç‚¹èŠ‚ç‚¹ID")
    metadata: Dict[str, Any] = Field(
        default_factory=lambda: {
            "created_at": time.time(), #åˆ›å»ºæ—¶é—´
            "last_used_at": time.time(), #æœ€åä½¿ç”¨æ—¶é—´  
            "revisit_count": 0, #å½“å‰æ€ç»´é“¾è¢«å›æº¯çš„æ¬¡æ•°
            "analysis_note": "", #å½“å‰æ€ç»´é“¾çš„åˆ†æè¯´æ˜
            "path_similarity": 0.0 #å½“å‰æ€ç»´é“¾ä¸è°œåº•çš„å…³è”åº¦
        },
        description="æ€ç»´é“¾å…ƒæ•°æ®"
    )

    def add_node(self, node_data: Dict[str, Any]) -> BrainNode:
        """æ·»åŠ èŠ‚ç‚¹
        
        Args:
            node_data: èŠ‚ç‚¹æ•°æ®å­—å…¸
            
        Returns:
            BrainNode: åˆ›å»ºçš„èŠ‚ç‚¹å®ä¾‹
        """
        # åˆ›å»º BrainNode å®ä¾‹
        node = BrainNode(**node_data)
        
        # æ·»åŠ åˆ°èŠ‚ç‚¹é›†åˆ
        self.nodes[node.id] = node
        self.current_focus_id = node.id
        
        return node

    def get_focus_path(self) -> List[BrainNode]:
        """è·å–æ‰€æœ‰èŠ‚ç‚¹ï¼ŒæŒ‰æ—¶é—´æˆ³æ’åº"""
        return sorted(self.nodes.values(), key=lambda x: x.timestamp)

class BrainChainMemory(BaseMemory):
    """
    æ€ç»´é“¾è®°å¿†ç±»ï¼Œç”¨äºç®¡ç†æ¸¸æˆä¸­çš„æ€ç»´é“¾ç»“æ„
    ç»§æ‰¿ BaseMemory ä»¥ä¾¿ä¸ LangChain ç”Ÿæ€é›†æˆ
    """
    memory_key: str = "brain_chain"
    brainchains: Dict[str, BrainChain] = {}
    current_chain_id: Optional[str] = None
    current_focus_id: Optional[str] = None
    action_type: Literal["creat_add", "inference", "no_action"] = "no_action"
    
    def __init__(self, **kwargs):
        super().__init__()
        self._via_agent_tool = False
        self.memory_key = kwargs.get("memory_key", "brain_chain")
        self.brainchains = kwargs.get("brainchains", {})
        self.current_chain_id = kwargs.get("current_chain_id", None)
        self.current_focus_id = kwargs.get("current_focus_id", None)
        
    def summarize_brainchains(self) -> str:
        """
        ç”Ÿæˆæ‰€æœ‰æ€ç»´é“¾çš„ç»“æ„åŒ–æ‘˜è¦
        
        Returns:
            str: æ ¼å¼åŒ–çš„æ€ç»´é“¾æ‘˜è¦
        """
        lines = []
        
        for chain_id, chain in self.brainchains.items():
            meta = chain.metadata
            lines.append(f"ğŸ”® æ€ç»´é“¾ {chain_id}")
            lines.append(f"  - åˆ›å»ºæ—¶é—´: {meta.get('created_at')}")
            lines.append(f"  - æœ€è¿‘ä½¿ç”¨: {meta.get('last_used_at')}")
            lines.append(f"  - è¢«è®¿é—®æ¬¡æ•°: {meta.get('revisit_count')}")
            lines.append(f"  - ç›¸ä¼¼æ€§åˆ†æ•°: {meta.get('path_similarity')}")
            lines.append(f"  - æ ¹èŠ‚ç‚¹ ID: {chain.root_node_id}")
            
            path = chain.get_focus_path()
            lines.append(f"  - ç„¦ç‚¹è·¯å¾„é•¿åº¦: {len(path)}")
            lines.append("  - èŠ‚ç‚¹è·¯å¾„:")
            
            for depth, node in enumerate(path):
                indent = "    " * (depth + 1)
                lines.append(f"{indent}ğŸ”¸ {node.content} ({node.id})")
                lines.append(f"{indent}â†³ å›å¤ç±»å‹: {node.reply_type}")
                if node.host_reply:
                    lines.append(f"{indent}â†³ å›ç­”å†…å®¹: {node.host_reply}")
                if node.notes:
                    lines.append(f"{indent}â†³ å¤‡æ³¨: {node.notes}")
                    
            lines.append("")  # æ¯æ¡é“¾ä¹‹é—´ç©ºè¡Œåˆ†éš”
            
        return "\n".join(lines)
    
    def create_chain(self) -> str:
        """
        åˆ›å»ºæ–°çš„æ€ç»´é“¾
        
        Returns:
            str: æ–°æ€ç»´é“¾ID
        """
        chain_id = str(uuid.uuid4())
        self.brainchains[chain_id] = BrainChain(chain_id=chain_id)
        self.current_chain_id = chain_id
        return chain_id
    
    def get_chain(self, chain_id: Optional[str] = None) -> Optional[BrainChain]:
        """
        è·å–æ€ç»´é“¾å®ä¾‹
        
        Args:
            chain_id: æ€ç»´é“¾IDï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›å½“å‰æ´»åŠ¨æ€ç»´é“¾
            
        Returns:
            Optional[BrainChain]: æ€ç»´é“¾å®ä¾‹
        """
        target_id = chain_id or self.current_chain_id
        return self.brainchains.get(target_id)
    
    def add_node(
        self,
        content: str,
        chain_id: str,
        host_reply: str,
        reply_type: str,
        notes: str,
        parent_id: Optional[str] = None,
    ) -> str:
        """
        å‘æŒ‡å®šçš„æ€ç»´é“¾ä¸­æ·»åŠ æ–°èŠ‚ç‚¹
        
        Args:
            content: èŠ‚ç‚¹å†…å®¹
            chain_id: æ€ç»´é“¾ID
            parent_id: çˆ¶èŠ‚ç‚¹IDï¼Œå¦‚æœä¸º None åˆ™ä½œä¸ºæ ¹èŠ‚ç‚¹
            host_reply: ä¸»æŒäººå›å¤å†…å®¹
            reply_type: å›å¤ç±»å‹
            notes: èŠ‚ç‚¹å¤‡æ³¨
            via_tool: æ˜¯å¦é€šè¿‡å·¥å…·æ·»åŠ 
            
        Returns:
            æ–°èŠ‚ç‚¹çš„ID
        """
            
        if chain_id not in self.brainchains:
            raise ValueError(f"æ€ç»´é“¾ {chain_id} ä¸å­˜åœ¨")
            
        chain = self.brainchains[chain_id]
        node_id = str(uuid.uuid4())
        timestamp = time.time()
        
        node_data = {
            "id": node_id,
            "content": content,
            "timestamp": timestamp,
            "parent_id": parent_id,
            "host_reply": host_reply,
            "reply_type": reply_type,
            "notes": notes
        }
        
        node = chain.add_node(node_data)
        self.current_focus_id = node_id
        logger.warning(f"æ·»åŠ èŠ‚ç‚¹ {node_id} åˆ°æ€ç»´é“¾ {chain_id}")
        return node_id
    
    @property
    def memory_variables(self) -> List[str]:
        """å®ç° BaseMemory æ¥å£ï¼Œè¿”å›è®°å¿†å˜é‡åˆ—è¡¨"""
        return [self.memory_key]

    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        åŠ è½½æ‰€æœ‰æ€ç»´é“¾çš„å®Œæ•´å†…å®¹
        
        Args:
            inputs: è¾“å…¥å‚æ•°å­—å…¸
            
        Returns:
            Dict[str, str]: åŒ…å«æ‰€æœ‰æ€ç»´é“¾å†…å®¹çš„å­—å…¸
        """
        return {
            self.memory_key: self.summarize_brainchains()
        }

    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:
        """
        å®ç° BaseMemory æ¥å£ï¼Œä¿å­˜ä¸Šä¸‹æ–‡
        
        Args:
            inputs: è¾“å…¥å‚æ•°å­—å…¸ï¼ŒåŒ…å«ç©å®¶é—®é¢˜
            outputs: è¾“å‡ºå‚æ•°å­—å…¸ï¼ŒåŒ…å«ä¸»æŒäººå›ç­”
        """
        logger.warning(f"save_context å¼€å§‹ï¼Œaction_type: {self.action_type}")
        if self.action_type == "creat_add":
            if isinstance(outputs, dict) and "output" in outputs and isinstance(outputs["output"], str):
                output_str = outputs["output"]
                logger.warning(f"âš ï¸ LLM è¾“å‡ºä¸ºå­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ JSONï¼š{output_str[:100]}...")

            match = re.search(r"\{[\s\S]*\}", output_str)
            if match:
                try:
                    outputs = json.loads(match.group(0))
                    logger.warning(f"âœ… è§£æåçš„ outputs: {outputs}")
                except Exception as e:
                    logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
                    return
            else:
                logger.error("âŒ æ— æ³•ä»è¾“å‡ºä¸­æå– JSON å¯¹è±¡ï¼Œè·³è¿‡ä¿å­˜")
                return
            structure_type = outputs.get("structure_type", "")
            question = inputs.get("question", "")
            host_reply = inputs.get("host_reply", "")
            reply_type = inputs.get("reply_type", "irrelevant")
            notes = inputs.get("notes", "")
            parent_id = outputs.get("parent_id", "")
            chain_id = outputs.get("chain_id", "")
            if not question or not host_reply:
                logger.warning("é—®é¢˜æˆ–å›ç­”ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
                return
                
            logger.warning(f"save_context å¼€å§‹ï¼Œç»“æ„ç±»å‹: {structure_type}")
            if structure_type == "new":
                chain_id = self.create_chain()
                self.add_node(
                    content=question,
                    chain_id=chain_id,
                    parent_id=None,
                    host_reply=host_reply,
                    reply_type=reply_type,
                    notes=notes
                )
            elif structure_type == "old":
                self.add_node(
                    content=question,
                    chain_id=chain_id,
                    parent_id=parent_id,
                    host_reply=host_reply,
                    reply_type=reply_type,
                    notes=notes
                )
            elif structure_type == "current":
                self.add_node(
                    content=question,
                    chain_id=self.current_chain_id,
                    parent_id=parent_id,
                    host_reply=host_reply,
                    reply_type=reply_type,
                    notes=notes
                )
            else:
                logger.warning("ç»“æ„ç±»å‹é”™è¯¯ï¼Œè·³è¿‡ä¿å­˜")
                return
            
            logger.warning(f"save_context ç»“æŸï¼Œå½“å‰æ€ç»´é“¾: {self.brainchains}\n"
                        f"å½“å‰ç„¦ç‚¹: {self.current_focus_id}\n"
                        f"å½“å‰æ€ç»´é“¾ID: {self.current_chain_id}")
        if self.action_type == "inference":
            if isinstance(outputs, dict) and "output" in outputs and isinstance(outputs["output"], str):
                output_str = outputs["output"]
                logger.warning(f"âš ï¸ LLM è¾“å‡ºä¸ºå­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ JSONï¼š{output_str[:100]}...")

            match = re.search(r"\{[\s\S]*\}", output_str)
            if match:
                try:
                    outputs = json.loads(match.group(0))
                    logger.warning(f"âœ… è§£æåçš„ outputs: {outputs}")
                except Exception as e:
                    logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
                    return
            else:
                logger.error("âŒ æ— æ³•ä»è¾“å‡ºä¸­æå– JSON å¯¹è±¡ï¼Œè·³è¿‡ä¿å­˜")
                return

            chain = self.get_chain(self.current_chain_id)
            if chain:
                chain.metadata["analysis_note"] = outputs.get("analysis_note", "")
                chain.metadata["path_similarity"] = outputs.get("path_similarity", 0.0)
        if self.action_type == "no_action":
            pass

    def clear(self) -> None:
        """
        å®ç° BaseMemory æ¥å£ï¼Œæ¸…é™¤æ‰€æœ‰è®°å¿†
        """
        self.brainchains.clear()
        self.current_chain_id = None
        logger.info("æ¸…é™¤æ‰€æœ‰æ€ç»´é“¾")

